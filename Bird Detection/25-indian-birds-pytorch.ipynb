{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Indian Bird Species Classification\n\nThis notebook demonstrates how to train a deep learning model to classify images of 25 different bird species found in India.\n\nTags: deep learning, computer vision, image classification, PyTorch\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader\nfrom sklearn.model_selection import KFold\nimport torch.nn.functional as F\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"26ecddc3-b88d-4f18-ab91-5a4d557f2f65","_cell_guid":"9cb4383e-a6d2-4e54-970b-1c9c163e695a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-14T16:21:14.314394Z","iopub.execute_input":"2023-04-14T16:21:14.315054Z","iopub.status.idle":"2023-04-14T16:21:17.694366Z","shell.execute_reply.started":"2023-04-14T16:21:14.315023Z","shell.execute_reply":"2023-04-14T16:21:17.693284Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Load and preprocess the dataset\n\nThis code loads and preprocesses a dataset of Indian bird species images using PyTorch. \n\nTo begin, the number of classes in the dataset is defined as `num_classes = 25`. This is a necessary step when training a classification model, as the model needs to know how many different classes to predict.\n\nNext, the directory containing the image dataset is specified using the `data_dir` variable. The dataset contains images of Indian bird species, which are organized into separate folders for each class.\n\nA series of data transformations are then defined using the `transforms.Compose()` function from PyTorch. This function takes a list of transform objects and applies them sequentially to each image. In this case, the following transformations are applied:\n\n- `transforms.Resize((224, 224))`: This transformation resizes each image to a fixed size of 224x224 pixels. This is a common size for image classification models.\n- `transforms.RandomHorizontalFlip()`: This transformation randomly flips each image horizontally with a probability of 0.5. This helps to increase the diversity of the training data and improve the model's robustness.\n- `transforms.ToTensor()`: This transformation converts each image to a PyTorch tensor. Tensors are the primary data structure used by PyTorch for training deep learning models.\n- `transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])`: This transformation normalizes each image with the mean and standard deviation values from the ImageNet dataset. Normalization helps to make the data more comparable across different images and can improve the convergence of the training process.\n\nFinally, the `datasets.ImageFolder()` function from PyTorch is used to create a PyTorch dataset from the image files. This function reads the images from the directory specified by `data_dir` and applies the transformations defined in `transform` to each image. The resulting dataset can be used for training a deep learning model to classify the images based on their bird species.","metadata":{}},{"cell_type":"code","source":"# Define the number of classes\nnum_classes = 25\n\n# Load the dataset\ndata_dir = \"/kaggle/input/25-indian-bird-species-with-226k-images\"\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ndataset = datasets.ImageFolder(data_dir, transform=transform)","metadata":{"_uuid":"5acebf1f-dd8f-43fb-951e-eb3c5b45a1e4","_cell_guid":"574a589e-3aed-42ba-8db3-23088385fe45","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-14T16:21:41.655954Z","iopub.execute_input":"2023-04-14T16:21:41.657163Z","iopub.status.idle":"2023-04-14T16:21:43.954225Z","shell.execute_reply.started":"2023-04-14T16:21:41.657108Z","shell.execute_reply":"2023-04-14T16:21:43.953239Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Define cross-validation splits\n\nThis code uses the `KFold` function from the scikit-learn library to define cross-validation splits for the dataset. Cross-validation is a common technique used in machine learning to evaluate the performance of a model on a limited dataset.\n\nTo create the cross-validation splits, the `KFold` function is used. This function takes several parameters, including `n_splits`, which specifies the number of folds to create. In this case, `n_splits=5`, which means that the dataset will be split into 5 equal-sized parts.\n\nThe `shuffle=True` parameter indicates that the data should be shuffled before splitting. This can help to ensure that each fold contains a diverse set of data and that the model is not biased towards any particular subset of the data.\n\nThe `random_state` parameter sets the random seed for reproducibility. By setting a random seed, the splits will be generated in a consistent manner each time the code is run, which can help with debugging and comparison of different models.\n","metadata":{}},{"cell_type":"code","source":"# Define the cross-validation splits\nkf = KFold(n_splits=5, shuffle=True, random_state=123)","metadata":{"_uuid":"8ea5ad12-e88f-4f2b-b213-480a6d7e2622","_cell_guid":"b0045765-3a97-4b6c-9cda-a3f2ccb8ce98","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-14T16:21:47.710730Z","iopub.execute_input":"2023-04-14T16:21:47.711441Z","iopub.status.idle":"2023-04-14T16:21:47.716246Z","shell.execute_reply.started":"2023-04-14T16:21:47.711403Z","shell.execute_reply":"2023-04-14T16:21:47.715160Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Train and evaluate the model using cross-validation\n\nThis code trains and evaluates a deep learning model using cross-validation. It uses a ResNet-18 architecture to classify images of Indian bird species into one of `num_classes` categories. \n\nThe `KFold` function is used to generate indices for the training and validation sets for each fold of the cross-validation process. For each fold, the `enumerate(kf.split(dataset))` function is used to obtain the indices of the training and validation data.\n\nThe model is defined using the `resnet18` function from PyTorch's `torchvision.models` module. The model is initialized with weights pre-trained on the ImageNet dataset, and the fully connected layer at the end of the network is replaced with a new layer that has `num_classes` output units. \n\nThe model is then moved to the GPU if available using the `to` method and the `device` variable. The loss function used to train the model is the `CrossEntropyLoss`, which is commonly used for multi-class classification tasks. The `Adam` optimizer is used to update the model weights during training.\n\nThe data is loaded into PyTorch `DataLoader` objects using the `SubsetRandomSampler` class. This sampler randomly samples a subset of the training or validation data for each batch of training or evaluation.\n\nThe model is trained for 10 epochs using the training data. During each epoch, the model is run through the training data in batches. The gradients of the loss function with respect to the model parameters are computed using the `backward` method and the weights are updated using the `step` method of the optimizer.\n\nAfter each epoch, the training loss is printed to the console. This provides a measure of how well the model is learning from the training data.\n\nThe model is then evaluated on the validation data using the `test_loader` object. The accuracy of the model on the validation data is computed by comparing the predicted labels to the true labels of the validation data.\n\nThis process is repeated for each fold of the cross-validation process. By using cross-validation, the code is able to obtain a more robust estimate of the model's performance than would be possible with a single train-test split. The final accuracy of the model is computed as the average of the accuracies obtained in each fold.\n\nThe trained model is saved to a file using the `save` method of the `torch.save` module, which saves the model parameters to a binary file. This allows the model to be reloaded later for use in other applications.","metadata":{}},{"cell_type":"code","source":"from torchvision.models import resnet18\n\n# Train and evaluate the model using cross-validation\nfor fold, (train_idx, test_idx) in enumerate(kf.split(dataset)):\n    print(f\"Fold {fold+1}\")\n    \n    # Define the model and move it to the GPU\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model = resnet18(pretrained=True)\n    model.fc = nn.Linear(model.fc.in_features, num_classes)\n    model = model.to(device)\n\n    # Define the loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n    test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n    train_loader = DataLoader(dataset, batch_size=64, sampler=train_sampler, num_workers=4, pin_memory=True)\n    test_loader = DataLoader(dataset, batch_size=64, sampler=test_sampler, num_workers=4, pin_memory=True)\n    for epoch in range(10):\n        running_loss = 0.0\n        for i, (inputs, labels) in enumerate(train_loader, 0):\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        print(f\"Epoch {epoch+1} loss: {running_loss/len(train_loader)}\")\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    print(f\"Accuracy: {correct/total}\")","metadata":{"_uuid":"c5d99628-c429-4a27-afb3-9e4a30a75e01","_cell_guid":"3802a708-5031-4916-824f-e0f80e61bdff","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-04-14T16:23:18.653118Z","iopub.execute_input":"2023-04-14T16:23:18.653634Z","iopub.status.idle":"2023-04-14T22:16:24.906757Z","shell.execute_reply.started":"2023-04-14T16:23:18.653599Z","shell.execute_reply":"2023-04-14T22:16:24.904627Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Fold 1\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/44.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a7bde4d43574d25a728d549dffca254"}},"metadata":{}},{"name":"stdout","text":"Epoch 1 loss: 0.025470126079035062\nEpoch 2 loss: 2.029125873262084e-05\nEpoch 3 loss: 1.52429088382941e-05\nEpoch 4 loss: 1.1793854078962863e-05\nEpoch 5 loss: 9.353173051296624e-06\nEpoch 6 loss: 7.509635585523128e-06\nEpoch 7 loss: 6.103404375158152e-06\nEpoch 8 loss: 5.014294697583263e-06\nEpoch 9 loss: 4.156751850874802e-06\nEpoch 10 loss: 3.4732735394841624e-06\nAccuracy: 1.0\nFold 2\nEpoch 1 loss: 0.02714827297781528\nEpoch 2 loss: 2.154370909669871e-05\nEpoch 3 loss: 1.6277350478177452e-05\nEpoch 4 loss: 1.2721924027355014e-05\nEpoch 5 loss: 1.0168118833880148e-05\nEpoch 6 loss: 8.241779323404119e-06\nEpoch 7 loss: 6.751573395434757e-06\nEpoch 8 loss: 5.584041047620718e-06\nEpoch 9 loss: 4.66400936766342e-06\nEpoch 10 loss: 3.907869145560675e-06\nAccuracy: 1.0\nFold 3\nEpoch 1 loss: 0.022968434523354776\nEpoch 2 loss: 2.318731055854344e-05\nEpoch 3 loss: 1.6988783474272578e-05\nEpoch 4 loss: 1.29002609236757e-05\nEpoch 5 loss: 1.0117977095825241e-05\nEpoch 6 loss: 8.071181047544794e-06\nEpoch 7 loss: 6.548884357471252e-06\nEpoch 8 loss: 5.3722185521270765e-06\nEpoch 9 loss: 4.453452729713418e-06\nEpoch 10 loss: 3.7150785256949106e-06\nAccuracy: 1.0\nFold 4\nEpoch 1 loss: 0.01970462221827098\nEpoch 2 loss: 1.795942065102487e-05\nEpoch 3 loss: 1.3783605335650114e-05\nEpoch 4 loss: 1.083817815432998e-05\nEpoch 5 loss: 8.684553600758353e-06\nEpoch 6 loss: 7.027793384777043e-06\nEpoch 7 loss: 5.73815692700999e-06\nEpoch 8 loss: 4.733008144648278e-06\nEpoch 9 loss: 3.9382791140529865e-06\nEpoch 10 loss: 3.28847522562975e-06\nAccuracy: 1.0\nFold 5\nEpoch 1 loss: 0.03211835697568894\nEpoch 2 loss: 2.8186950047367563e-05\nEpoch 3 loss: 2.046578366347661e-05\nEpoch 4 loss: 1.552034083538065e-05\nEpoch 5 loss: 1.2044145034785734e-05\nEpoch 6 loss: 9.602720059736018e-06\nEpoch 7 loss: 7.733903894147546e-06\nEpoch 8 loss: 6.312871370966424e-06\nEpoch 9 loss: 5.208018818954413e-06\nEpoch 10 loss: 4.324261338911048e-06\nAccuracy: 1.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Save the trained model\n\nThis code saves the trained ResNet-18 model to a file specified by the `model_path` variable using the `state_dict()` function from PyTorch. This function returns a dictionary containing the parameters and persistent buffers of the model, which can be used to save and load the model's state. \n\nThe saved model can be loaded later using the `load_state_dict()` function from PyTorch. This allows you to reuse the trained model for inference or further training without having to retrain the model from scratch.\n","metadata":{}},{"cell_type":"code","source":"# Save the trained model\nmodel_path = \"/kaggle/working/trained_resnet18.pth\"\ntorch.save(model.state_dict(), model_path)","metadata":{"execution":{"iopub.status.busy":"2023-04-14T22:16:43.192690Z","iopub.execute_input":"2023-04-14T22:16:43.193072Z","iopub.status.idle":"2023-04-14T22:16:43.276471Z","shell.execute_reply.started":"2023-04-14T22:16:43.193034Z","shell.execute_reply":"2023-04-14T22:16:43.275438Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}